[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Divvy Bike Analysis",
    "section": "",
    "text": "Public bike share (PBS).\nA PBS is an extension of the existing transit system with a network of short-term, self-service bicycle posts in which:\n\nUsers can use bikes by purchasing casual day use or annual memberships,\nUsers can ride bikes for a short distance for one-way trips within a defined service area and Station locations can change overtime based on ridership practices or operation needs.\n\nBike share technology continues to evolve quickly along with other wireless and digital changes. Other recent advancements include systems that do not require docking stations i.e. “smart lock” systems and electric‐assist bikes.\n\n\nI used 1 year (12 Months) of Divvy Chicago Bike Sharing Data from Jan 2024 to Dec 2024, obtained from Divvy Bike .\nThis dataset included 5,667,986 trips, of which 3,127,293 / 55.2% were made by annual or monthly members, and 2,540,693 / 44.8% by casual users.\n\n\nAlthough this dataset is not a result of a survey, The following missing features could make this analysis more interesting and stronger if were exist.\n\nBike ID,\nUser ID,\nUser Gender,\nUser Age,\nPurpose of trip,\nTrip distance and\nWeather conditions.\n\nI believe some of them are connected to the agreed privacy policy!\nAnyway, let’s load the packages we need for this brief analysis\n\n\nCode\nlibrary(tidyverse)\nlibrary(paletteer)\nlibrary(PNWColors) \nlibrary(leaflet)\nscale_colour_paletteer_d(\"PNWColors::Sunset\")\nscale_fill_paletteer_d(\"PNWColors::Sunset\")\ntheme_set(theme_minimal())\n\n\nHere, tidyverse is for analysis, paletteer is for creating custom color pallete, and leaflet is for creating maps."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Divvy Bike Analysis",
    "section": "",
    "text": "Public bike share (PBS).\nA PBS is an extension of the existing transit system with a network of short-term, self-service bicycle posts in which:\n\nUsers can use bikes by purchasing casual day use or annual memberships,\nUsers can ride bikes for a short distance for one-way trips within a defined service area and Station locations can change overtime based on ridership practices or operation needs.\n\nBike share technology continues to evolve quickly along with other wireless and digital changes. Other recent advancements include systems that do not require docking stations i.e. “smart lock” systems and electric‐assist bikes.\n\n\nI used 1 year (12 Months) of Divvy Chicago Bike Sharing Data from Jan 2024 to Dec 2024, obtained from Divvy Bike .\nThis dataset included 5,667,986 trips, of which 3,127,293 / 55.2% were made by annual or monthly members, and 2,540,693 / 44.8% by casual users.\n\n\nAlthough this dataset is not a result of a survey, The following missing features could make this analysis more interesting and stronger if were exist.\n\nBike ID,\nUser ID,\nUser Gender,\nUser Age,\nPurpose of trip,\nTrip distance and\nWeather conditions.\n\nI believe some of them are connected to the agreed privacy policy!\nAnyway, let’s load the packages we need for this brief analysis\n\n\nCode\nlibrary(tidyverse)\nlibrary(paletteer)\nlibrary(PNWColors) \nlibrary(leaflet)\nscale_colour_paletteer_d(\"PNWColors::Sunset\")\nscale_fill_paletteer_d(\"PNWColors::Sunset\")\ntheme_set(theme_minimal())\n\n\nHere, tidyverse is for analysis, paletteer is for creating custom color pallete, and leaflet is for creating maps."
  },
  {
    "objectID": "index.html#reading-the-datasets",
    "href": "index.html#reading-the-datasets",
    "title": "Divvy Bike Analysis",
    "section": "Reading the datasets",
    "text": "Reading the datasets\nHere, we used read.csv function to read all 12 months into the dataset in R.\n\n\nCode\njanuary &lt;- read.csv(\"datasets/202401-divvy-tripdata.csv\")\nfebruary &lt;- read.csv(\"datasets/202402-divvy-tripdata.csv\")\nmarch &lt;- read.csv(\"datasets/202403-divvy-tripdata.csv\")\napril &lt;- read.csv(\"datasets/202404-divvy-tripdata.csv\")\nmay &lt;- read.csv(\"datasets/202405-divvy-tripdata.csv\")\njune &lt;- read.csv(\"datasets/202406-divvy-tripdata.csv\")\njuly &lt;- read.csv(\"datasets/202407-divvy-tripdata.csv\")\naugust &lt;- read.csv(\"datasets/202408-divvy-tripdata.csv\")\nseptember &lt;- read.csv(\"datasets/202409-divvy-tripdata.csv\")\noctober &lt;- read.csv(\"datasets/202410-divvy-tripdata.csv\")\nnovember &lt;- read.csv(\"datasets/202411-divvy-tripdata.csv\")\ndecember &lt;- read.csv(\"datasets/202412-divvy-tripdata.csv\")"
  },
  {
    "objectID": "index.html#combining-the-datasets",
    "href": "index.html#combining-the-datasets",
    "title": "Divvy Bike Analysis",
    "section": "Combining the datasets",
    "text": "Combining the datasets\nHere, we combine all monthly datasets into a single dataset for easier analysis. Additionally, a month column is added to each dataset to identify the month of each ride.\n\n\nCode\ndf &lt;- bind_rows(\n    january |&gt; mutate(month = 1),\n    february |&gt;  mutate(month = 2),\n    march|&gt;  mutate(month = 3),\n    april|&gt;  mutate(month = 4),\n    may|&gt;  mutate(month = 5),\n    june|&gt;  mutate(month = 6),\n    july |&gt; mutate(month = 7),\n    august |&gt; mutate(month = 8),\n    september |&gt; mutate(month = 9),\n    october |&gt; mutate(month = 10),\n    november |&gt; mutate(month = 11),\n    december|&gt;  mutate(month = 12)\n)"
  },
  {
    "objectID": "index.html#creating-new-columns",
    "href": "index.html#creating-new-columns",
    "title": "Divvy Bike Analysis",
    "section": "Creating New Columns",
    "text": "Creating New Columns\nTo enhance our analysis, we derive new columns such as time_of_day using the hour function from the lubridate package, and season using the month function.\n\n\nCode\ndf &lt;- df |&gt;\n    mutate(hour = hour(started_at)) |&gt;\n    mutate(time_of_day = \n    case_when (\n      hour %in% 0:5 ~ \"Night\",\n      hour %in% 6:11 ~ \"Morning\",\n      hour %in% 12:17 ~ \"Afternoon\",\n      hour %in% 18:23 ~ \"Evening\"\n        )\n    )\n\n\nSimlarly, we derive the season column using the month from the dataframe.\n\n\nCode\ndf &lt;- df  |&gt;\n    mutate(season = \n    case_when (\n        month %in% c(12, 1, 2) ~ \"Winter\",\n        month %in% c(3, 4, 5) ~ \"Spring\",\n        month %in% c(6, 7, 8) ~ \"Summer\",\n        month %in% c(9, 10, 11) ~ \"Fall\"\n    )\n)"
  },
  {
    "objectID": "index.html#ride-type-by-rider",
    "href": "index.html#ride-type-by-rider",
    "title": "Divvy Bike Analysis",
    "section": "Ride Type by Rider",
    "text": "Ride Type by Rider\n\n\nCode\nride_type_by_user &lt;- df |&gt;\n    group_by(member_casual) |&gt;\n    summarise(count = n()) |&gt;\n    mutate(\n        proportion = count / sum(count),\n        percentage = count / sum(count) * 100,\n    )\n\nride_type_by_user |&gt;\n    mutate(\n        start = lag(proportion, default = 0) * 2 * pi,\n        end = cumsum(proportion) * 2 * pi,\n    ) |&gt;\n    ggplot() +\n    ggforce::geom_arc_bar(\n        aes(\n            x0 = 0, y0 = 0,\n            r0 = 0.7, r = 1,\n            start = start, \n            end = end,\n            fill = member_casual  # Ensure 'fill' is mapped to a variable\n        )\n    ) +\n    annotate(\n      'text',  \n      x = 0,\n      y = 0,\n      label = paste0(round(nrow(df) / 1000000, 2), \"M\\nTotal\\nRides\"),\n      size = 7,\n      lineheight = 1\n    ) +\n    coord_equal(expand = FALSE, xlim = c(-1.1, 1.1), ylim = c(-1.1, 1.1)) +\n    theme_void(base_size = 16) +\n    labs(\n        fill = \"Membership Type\"  # Add a meaningful label for the legend\n    ) +\n    theme(\n        legend.position = \"right\",  # Place the legend on the right\n        legend.margin = margin(t = 1, b = 0.5, unit = 'cm'), \n        legend.text = element_text(size = 15)\n    ) +\n    scale_fill_manual(\n        values = pnw_palette(\"Sunset\", n = 2),\n        labels = c(\"Casual\", \"Member\")  # Custom labels for legend categories\n    )\n\n\n\n\n\n\n\n\n\nObservations:\n\n55.2% of rides were made by members, while 44.8% were made by casual users."
  },
  {
    "objectID": "index.html#ride-type-by-rideable",
    "href": "index.html#ride-type-by-rideable",
    "title": "Divvy Bike Analysis",
    "section": "Ride Type By Rideable",
    "text": "Ride Type By Rideable\nIn this section, we examine ride type based on bike types (classic, electric, docked) and user categories. The data is visualized as a stacked bar chart to highlight usage trends.\n\n\nCode\nride_type_by_rideable &lt;- df |&gt;\n    group_by(rideable_type, member_casual) |&gt;\n    summarise(count = n(), .groups = 'drop')\n\nggplot(ride_type_by_rideable, aes(x = rideable_type, y = count, fill = member_casual)) +\n    geom_bar(stat = \"identity\", position = \"stack\", width = 0.7) +\n    labs(\n        x = \"Bike Type\",\n        y = \"Count\",\n        fill = \"User Type\"\n    ) +\n    theme_minimal(base_size = 15) +\n    scale_fill_manual(values = pnw_palette(\"Sunset\", n = 2), labels = c(\"Casual\", \"Member\"))  \n\n\n\n\n\n\n\n\n\nThis block of code visualizes the number of rides for each bike type (classic, electric, docked) based on user type (member or casual) using a stacked bar chart. It groups the data by bike type and user type, counts the rides, and then plots this information with bars filled by user type.\nObservations:\n\nClassic bikes are more popular among members than casual users.\nElectric bikes are more popular among casual users than members."
  },
  {
    "objectID": "index.html#average-ride-length",
    "href": "index.html#average-ride-length",
    "title": "Divvy Bike Analysis",
    "section": "Average Ride Length",
    "text": "Average Ride Length\n\n\nCode\n## Average Ride Length\naverage_ride_length &lt;- df |&gt;\n    mutate(ride_length = as.numeric(difftime(ended_at, started_at, units = \"mins\"))) |&gt;\n    group_by(member_casual) |&gt;\n    summarise(average_ride_length = mean(ride_length, na.rm = TRUE))\n\nggplot(average_ride_length, aes(x = member_casual, y = average_ride_length, fill = member_casual)) +\n    geom_bar(stat = \"identity\", width = 0.7) +\n    geom_text(aes(label = round(average_ride_length, 1)), vjust = -0.5, size = 5) +\n     theme(legend.position = \"none\")+\n  scale_fill_manual(values = pnw_palette(\"Sunset\", n = 2), labels = c(\"Casual\", \"Member\")) +\n    labs(\n        x = \"User Type\",\n        y = \"Average Ride Length (minutes)\",\n        fill = \"Member Type\"\n    ) +\n    theme_minimal(base_size = 15)\n\n\n\n\n\n\n\n\n\nThis block of code calculates the average ride length for each user type (member or casual) and visualizes it in a bar chart. It groups the data by user type, computes the average ride length, and then plots this information with bars filled by user type.\nObservations:\n\nThe average ride length is significantly longer for casual riders compared to members.\nThe average ride length for both members and casual riders is around 20 minutes."
  },
  {
    "objectID": "index.html#ride-length-by-weekday",
    "href": "index.html#ride-length-by-weekday",
    "title": "Divvy Bike Analysis",
    "section": "Ride Length by Weekday",
    "text": "Ride Length by Weekday\n\n\nCode\nride_length_by_weekday &lt;- df |&gt;\n    mutate(ride_length = as.numeric(difftime(ended_at, started_at, units = \"mins\")),\n           day_of_week = weekdays(as.Date(started_at))) |&gt;\n    group_by(day_of_week) |&gt;\n    summarise(average_ride_length = mean(ride_length, na.rm = TRUE)) |&gt; \n    mutate(day_of_week = fct_relevel(day_of_week, c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")))\n\nggplot(ride_length_by_weekday, aes(x = day_of_week, y = average_ride_length, fill = day_of_week)) +\n    geom_bar(stat = \"identity\", width = 0.7) +\n    geom_text(aes(label = round(average_ride_length, 1)), vjust = -0.5, size = 5) +\n    labs(\n        x = \"Day of the Week\",\n        y = \"Average Ride Length (minutes)\"\n    ) +\n    theme(legend.position = \"none\") +\n    scale_fill_manual(values = pnw_palette(\"Sunset\", n = 7))\n\n\n\n\n\n\n\n\n\nThis block of code calculates the average ride length for each day of the week and visualizes it in a bar chart. It groups the data by day of the week, computes the average ride length, and then plots this information with bars filled by the day of the week.\nObservations:\n\nThe average ride length is longest on Mondays, followed by Tuesdays, Wednesdays, Thursdays, Fridays, Saturdays, and Sundays.\nThe average ride length is significantly longer for casual riders compared to members."
  },
  {
    "objectID": "index.html#total-rides-by-weekday",
    "href": "index.html#total-rides-by-weekday",
    "title": "Divvy Bike Analysis",
    "section": "Total Rides By Weekday",
    "text": "Total Rides By Weekday\nLet’s look at the total rides by weekday.\n\n\nCode\ntotal_rides_by_weekday &lt;- df |&gt;\n    mutate(day_of_week = weekdays(as.Date(started_at))) |&gt;\n    group_by(day_of_week) |&gt;\n    summarise(total_rides = n()) |&gt;\n    mutate(day_of_week = fct_relevel(day_of_week, c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")))\n\ntotal_rides_by_weekday |&gt;\n    ggplot(aes(x = day_of_week, y = total_rides, fill = day_of_week)) +\n    geom_bar(stat = \"identity\", width = 0.7) +\n    geom_text(aes(label = total_rides), vjust = -0.5, size = 5) +\n  theme(legend.position = \"none\")+\n  scale_fill_manual(values = pnw_palette(\"Sunset\", n = 7))\n\n\n\n\n\n\n\n\n\nThis block of code calculates the total number of rides for each day of the week and visualizes it in a bar chart. It groups the data by day of the week, counts the total rides, and then plots this information with bars filled by the day of the week.\nObservations:\n\nThe highest number of rides occurs on Saturdays, followed by Sundays, Fridays, Thursdays, Wednesdays, Tuesdays, and Mondays.\nThe lowest number of rides occurs on Mondays."
  },
  {
    "objectID": "index.html#total-rides-by-hour",
    "href": "index.html#total-rides-by-hour",
    "title": "Divvy Bike Analysis",
    "section": "Total Rides by Hour",
    "text": "Total Rides by Hour\nLet’s take a look at the total rides by hour and time of day.\n\n\nCode\ntotal_rides_by_hour &lt;- df |&gt;\n    mutate(hour = hour(started_at)) |&gt;\n    group_by(hour, time_of_day) |&gt;\n    summarise(total_rides = n(), .groups = 'drop')\n\ntotal_rides_by_hour |&gt;\n    ggplot(aes(x = hour, y = total_rides, fill = time_of_day)) +\n    geom_bar(stat = \"identity\", width = 0.7) +\n    scale_x_continuous(breaks = 0:23) +\n    labs(\n        x = \"Hour of the Day\",\n        y = \"Total Rides\",\n        fill = \"Time of Day\"\n    ) +\n    theme_minimal(base_size = 15) + scale_fill_manual(values = pnw_palette(\"Sunset\", n = 4))\n\n\n\n\n\n\n\n\n\nThis block of code calculates the total number of rides for each hour of the day and visualizes it in a bar chart. It groups the data by hour and time of day, counts the total rides, and then plots this information with bars filled by time of day.\nObservations:\n\nThe highest number of rides occurs between 5 PM and 7 PM.\nThe lowest number of rides occurs between 12 AM and 6 AM.\nThe number of rides is highest on weekends, particularly on Saturdays.\nThe number of rides is lowest on Mondays."
  },
  {
    "objectID": "index.html#total-rides-by-month",
    "href": "index.html#total-rides-by-month",
    "title": "Divvy Bike Analysis",
    "section": "Total Rides by Month",
    "text": "Total Rides by Month\nNow let’s look at the total rides by month and season.\n\n\nCode\ntotal_rides_by_month &lt;- df |&gt;\n    mutate(month = month(started_at, label = TRUE)) |&gt;\n    group_by(month, season) |&gt;\n    summarise(total_rides = n(), .groups = 'drop')\n\ntotal_rides_by_month |&gt;\n    ggplot(aes(x = month, y = total_rides, fill = season)) +\n    geom_bar(stat = \"identity\", width = 0.7) +\n    labs(\n        x = \"Month\",\n        y = \"Total Rides\",\n        fill = \"Season\"\n    ) + scale_fill_manual(values = pnw_palette(\"Sunset\", n = 4))\n\n\n\n\n\n\n\n\n\nObservations:\n\nThe highest number of rides occurred in the summer, followed by fall, spring, and winter.\n\nThe total number of rides is slightly higher for casual riders compared to members\n\nAverage Ride Length by Season\n\n\n\nCode\naverage_ride_length_by_season &lt;- df |&gt;\n    mutate(ride_length = as.numeric(difftime(ended_at, started_at, units = \"mins\"))) |&gt;\n    group_by(season) |&gt;\n    summarise(average_ride_length = mean(ride_length, na.rm = TRUE), .groups = 'drop')\n\nggplot(average_ride_length_by_season, aes(x = season, y = average_ride_length, fill = season)) +\n    geom_bar(stat = \"identity\", width = 0.7) +\n    geom_text(aes(label = round(average_ride_length, 1)), vjust = -0.5, size = 5, color = \"white\") +\n    labs(\n        x = \"Season\",\n        y = \"Average Ride Length (minutes)\",\n        fill = \"Season\"\n    ) +\n    scale_fill_manual(values = pnw_palette(\"Sunset\", n = 4))\n\n\n\n\n\n\n\n\n\nObservations:\n\nThe average ride length is shortest in the summer and longest in the summer.\nThe average ride length is significantly longer for casual riders compared to members."
  },
  {
    "objectID": "index.html#top-10-starting-stations",
    "href": "index.html#top-10-starting-stations",
    "title": "Divvy Bike Analysis",
    "section": "Top 10 Starting Stations",
    "text": "Top 10 Starting Stations\nThe top 10 stations will be visualized on a map to show their locations and the number of rides starting from each station. The code uses the leaflet library to create an interactive map with clustered markers for the top 10 starting locations of bike rides. The map displays the number of rides starting from each location, providing a visual representation of popular bike stations in Chicago.\n\n\nCode\ndf |&gt;\n  mutate(start_station_name = fct_lump(start_station_name, 10)) |&gt; \n  count(start_station_id, start_station_name, name = \"counts\", sort = T) |&gt; \n  filter(!is.na(start_station_name),\n         !is.na(start_station_id),\n         start_station_name != \"Other\") |&gt;\n  mutate(start_station_name = fct_reorder(start_station_name, counts)) |&gt;\n  top_n(n=11) |&gt;\n  slice(-1) |&gt;\n  ggplot(aes(x = start_station_name, y = counts, fill = start_station_name)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  theme(legend.position = \"none\") +\n  labs(y = \"Count\", x = \"Start Stations\")+\n  scale_fill_manual(values = pnw_palette(\"Sunset\", n = 10))\n\n\n\n\n\n\n\n\n\nNow let’s look at them on the map.\n\n\nCode\ntop_start_location &lt;- df |&gt;\n  group_by(start_lat, start_lng) |&gt;\n  summarise(counts = n(), .groups = 'drop') |&gt;\n  slice_max(order_by = counts, n = 10)\n\nleaflet(top_start_location) |&gt;\n  addTiles() |&gt;\n  addMarkers(lng = ~start_lng, lat = ~start_lat, popup = ~counts, clusterOptions = markerClusterOptions())\n\n\n\n\n\n\n This code groups the data by starting latitude and longitude, then summarizes the counts of occurrences for each group. It selects the top 10 locations with the highest counts and creates a Leaflet map. The map displays markers at the specified locations with popups showing the counts and enables marker clustering.\nObservations:\n\nMost of the Locations are around the downtown and UChicago-Northwestern area.\nThe most popular starting and ending stations are very to each other."
  },
  {
    "objectID": "index.html#top-10-ending-stations",
    "href": "index.html#top-10-ending-stations",
    "title": "Divvy Bike Analysis",
    "section": "Top 10 Ending Stations",
    "text": "Top 10 Ending Stations\nThe top 10 ending stations will be visualized on a map to show their locations and the number of rides ending at each station. The code uses the leaflet library to create an interactive map with clustered markers for the top 10 ending locations of bike rides. The map displays the number of rides ending at each location, providing a visual representation of popular bike stations in Chicago."
  },
  {
    "objectID": "index.html#top-10-ending-stations-1",
    "href": "index.html#top-10-ending-stations-1",
    "title": "Divvy Bike Analysis",
    "section": "Top 10 Ending Stations",
    "text": "Top 10 Ending Stations\n\n\nCode\ndf |&gt;\n    mutate(end_station_name = fct_lump(end_station_name, 10)) |&gt; \n    count(end_station_id, end_station_name, name = \"counts\", sort = T) |&gt; \n    filter(!is.na(end_station_name),\n                 !is.na(end_station_id),\n                 end_station_name != \"Other\") |&gt;\n    mutate(end_station_name = fct_reorder(end_station_name, counts)) |&gt; \n    top_n(n = 11) |&gt;\n    slice(-1) |&gt;\n    ggplot(aes(x = end_station_name, y = counts, fill = end_station_name)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() + \n  theme(legend.position = \"none\") +\n  labs(y = \"Count\", x = \"End Stations\")+\n  scale_fill_manual(values = pnw_palette(\"Sunset\", n = 10))\n\n\n\n\n\n\n\n\n\nLet’s look at them on the map.\n\n\nCode\ntop_end_location &lt;- df |&gt;\n  group_by(end_lat, end_lng) |&gt;\n  summarise(counts = n(), .groups = 'drop') |&gt;\n  slice_max(order_by = counts, n = 10)\n\nleaflet(top_end_location) |&gt;\n  addTiles() |&gt;\n  addMarkers(lng = ~end_lng, lat = ~end_lat, popup = ~counts, clusterOptions = markerClusterOptions())\n\n\n\n\n\n\n The first part of the code uses the ggplot2 library to create a horizontal bar plot of the top end stations by count. It groups the data by end_station_name, calculates the counts, and then plots these counts with bars filled by the station names, flipping the coordinates for better readability. The second part of the code uses the leaflet library to create an interactive map showing the top 10 end locations based on counts. It groups the data by latitude and longitude, calculates the counts, and then adds markers to the map at these locations, with popups displaying the counts and clustering options enabled for better visualization.\nObservations:\n\nMost of the Locations are around the downtown and UChicago-Northwestern area.\nThe most popular starting and ending stations are very to each other."
  },
  {
    "objectID": "about_me.html",
    "href": "about_me.html",
    "title": "Farhan Sadeek",
    "section": "",
    "text": "Math, Physics and CS Student\nStudent Software Engineer\n\n\nHello, I’m Farhan Sadeek, a student at The Ohio State University. My passion lies in the dynamic realms of Software Development, Machine Learning, and Artificial Intelligence. As an active member of the AI Club and enthusiastic participant in competitive programming, I thrive on exploring innovative solutions to complex challenges. A dedication to understanding marks my academic journey the intricacies of computer science and applying theoretical knowledge to real-world scenarios.\n\n\n\n\n\n\n\nJanuary 2024 - Present\nThe Ohio State University\nI will be working on a research project on the impact of U.S. natural disasters on individuals with diverse identities, advised by Dr. Kelsea Best. Using Python (pandas, matplotlib) and R (Tidyverse, ggplot2) for data visualization, I will attend weekly Zoom meetings to report updates and deliver presentations.\n\n\n\nJune 2023 - Present\nSpectrum\nI collaboratively resolved complex issues cross-functionally, leveraging statistical methodologies that led to a 15% improvement in team satisfaction. Additionally, I demonstrated advanced research knowledge, consistently exceeding targets and achieving a 10% increase in project milestones and academic standards through rigorous statistical analysis.\n\n\n\nAugust 2021 - Present\nGoogle AI\nI leveraged my expertise in Kaggle datasets to analyze and extract valuable insights, driving data-driven decision-making and enhancing business performance. Through developing and implementing advanced machine learning models and algorithms, I achieved a 20% improvement in solving complex problems and optimizing business processes. Collaborating with cross-functional teams, I effectively communicated findings from Kaggle datasets, enabling stakeholders to make informed decisions and contributing to a 10% increase in desired outcomes.\n\n\n\nMay 2022 - August 2022\nHarvard University\nDeveloped Dr. Kane’s Harvard Class GOV 1005 with R coding language along with other student researchers. Four weeks of training under Dr. Kane culminated in an independent Data Analytics Research Project, where I analysed the impact of different economic indices on the population of a country.\n\n\n\n\n\n\n\nMay 2027\nRelevant Coursework:\n\nMath 4580: Abstract Algebra I\n\n\n\nMath 4547: Real Analysis I\nMath 4573: Number Theory\nStat 4202: Mathematical Statistics II\nPhysics 2301: Relativistic Mechanics\nMath 4512: Partial Differential Equations\nStat 4201: Mathematical Statistics I\nStat 3470: Engineering Statistics\nMath 3345: Mathematical Proofs\nMath 2568: Linear Algebra\nMath 2153: Multivariable Calculus\nPhysics 2300: Classical Mechanics\nCSE 2321: Discrete Math\nCSE 2231: Software Development\nCSE 2221: Software Components\n\n\n\n\n\n\n\n\n\nAs a member of the Competitive Programming Club at Ohio State University, I actively participate in programming competitions and challenges. Through these experiences, I have enhanced my problem-solving skills and developed efficient coding techniques. I have gained valuable experience in tackling complex programming challenges and improving my algorithmic thinking. Additionally, I have collaborated with fellow programming enthusiasts to enhance our skills and knowledge through group projects and coding sessions.\n\n\n\nAs a member of the Big Data and Analytics Association, I gained hands-on experience with data analytics tools like Tableau, PowerBI, and AWS. Through workshops, seminars, and projects, I learned to analyze large datasets, identify patterns, and derive meaningful insights. The association also provided networking opportunities with industry professionals and experts in the field.\n\n\n\nThe Artificial Intelligence Club was crucial to my career development. Through their meetings, workshops, and projects, I learned machine learning libraries such as Sci-kit Learn, PyTorch, and TensorFlow. I gained hands-on experience in developing and implementing machine learning models, natural language processing algorithms, and computer vision applications. The club organized guest lectures and industry talks, allowing me to learn from experts in the field and gain insights into real-world AI applications.\n\n\n\n\n\n\n\n\nPython: 20,000 lines\nC++: 20,000 lines\nJava: 10,000 lines\nHTML: 10,000 lines\nCSS: 10,000 lines\nJavascript: 3,000 lines\nNode JS: 1,000 lines\nReact.js: 1,000 lines\nDjango: 3,000 lines\nGit: &gt; 3 years\n\n\n\n\n\nSeaborn: 10,000 lines\nTableau: &gt; 2 years\nPyTorch: 5,000 lines\nTensorflow: 5,000 lines\nScikit-Learn: 3,000 lines\nSQL: 3,000 lines\nDocker: &lt; 1 year\nAWS/Azure: 1 year\n\n\n\n\n\n\nEmail: farhansadeek019@gmail.com\nLinkedIn: farhansadeekde110\nX: SadeekFarhan21"
  },
  {
    "objectID": "about_me.html#about-me",
    "href": "about_me.html#about-me",
    "title": "Farhan Sadeek",
    "section": "",
    "text": "Hello, I’m Farhan Sadeek, a student at The Ohio State University. My passion lies in the dynamic realms of Software Development, Machine Learning, and Artificial Intelligence. As an active member of the AI Club and enthusiastic participant in competitive programming, I thrive on exploring innovative solutions to complex challenges. A dedication to understanding marks my academic journey the intricacies of computer science and applying theoretical knowledge to real-world scenarios."
  },
  {
    "objectID": "about_me.html#professional-journey",
    "href": "about_me.html#professional-journey",
    "title": "Farhan Sadeek",
    "section": "",
    "text": "January 2024 - Present\nThe Ohio State University\nI will be working on a research project on the impact of U.S. natural disasters on individuals with diverse identities, advised by Dr. Kelsea Best. Using Python (pandas, matplotlib) and R (Tidyverse, ggplot2) for data visualization, I will attend weekly Zoom meetings to report updates and deliver presentations.\n\n\n\nJune 2023 - Present\nSpectrum\nI collaboratively resolved complex issues cross-functionally, leveraging statistical methodologies that led to a 15% improvement in team satisfaction. Additionally, I demonstrated advanced research knowledge, consistently exceeding targets and achieving a 10% increase in project milestones and academic standards through rigorous statistical analysis.\n\n\n\nAugust 2021 - Present\nGoogle AI\nI leveraged my expertise in Kaggle datasets to analyze and extract valuable insights, driving data-driven decision-making and enhancing business performance. Through developing and implementing advanced machine learning models and algorithms, I achieved a 20% improvement in solving complex problems and optimizing business processes. Collaborating with cross-functional teams, I effectively communicated findings from Kaggle datasets, enabling stakeholders to make informed decisions and contributing to a 10% increase in desired outcomes.\n\n\n\nMay 2022 - August 2022\nHarvard University\nDeveloped Dr. Kane’s Harvard Class GOV 1005 with R coding language along with other student researchers. Four weeks of training under Dr. Kane culminated in an independent Data Analytics Research Project, where I analysed the impact of different economic indices on the population of a country."
  },
  {
    "objectID": "about_me.html#education",
    "href": "about_me.html#education",
    "title": "Farhan Sadeek",
    "section": "",
    "text": "May 2027\nRelevant Coursework:\n\nMath 4580: Abstract Algebra I\n\n\n\nMath 4547: Real Analysis I\nMath 4573: Number Theory\nStat 4202: Mathematical Statistics II\nPhysics 2301: Relativistic Mechanics\nMath 4512: Partial Differential Equations\nStat 4201: Mathematical Statistics I\nStat 3470: Engineering Statistics\nMath 3345: Mathematical Proofs\nMath 2568: Linear Algebra\nMath 2153: Multivariable Calculus\nPhysics 2300: Classical Mechanics\nCSE 2321: Discrete Math\nCSE 2231: Software Development\nCSE 2221: Software Components"
  },
  {
    "objectID": "about_me.html#outside-school-work",
    "href": "about_me.html#outside-school-work",
    "title": "Farhan Sadeek",
    "section": "",
    "text": "As a member of the Competitive Programming Club at Ohio State University, I actively participate in programming competitions and challenges. Through these experiences, I have enhanced my problem-solving skills and developed efficient coding techniques. I have gained valuable experience in tackling complex programming challenges and improving my algorithmic thinking. Additionally, I have collaborated with fellow programming enthusiasts to enhance our skills and knowledge through group projects and coding sessions.\n\n\n\nAs a member of the Big Data and Analytics Association, I gained hands-on experience with data analytics tools like Tableau, PowerBI, and AWS. Through workshops, seminars, and projects, I learned to analyze large datasets, identify patterns, and derive meaningful insights. The association also provided networking opportunities with industry professionals and experts in the field.\n\n\n\nThe Artificial Intelligence Club was crucial to my career development. Through their meetings, workshops, and projects, I learned machine learning libraries such as Sci-kit Learn, PyTorch, and TensorFlow. I gained hands-on experience in developing and implementing machine learning models, natural language processing algorithms, and computer vision applications. The club organized guest lectures and industry talks, allowing me to learn from experts in the field and gain insights into real-world AI applications."
  },
  {
    "objectID": "about_me.html#skills",
    "href": "about_me.html#skills",
    "title": "Farhan Sadeek",
    "section": "",
    "text": "Python: 20,000 lines\nC++: 20,000 lines\nJava: 10,000 lines\nHTML: 10,000 lines\nCSS: 10,000 lines\nJavascript: 3,000 lines\nNode JS: 1,000 lines\nReact.js: 1,000 lines\nDjango: 3,000 lines\nGit: &gt; 3 years\n\n\n\n\n\nSeaborn: 10,000 lines\nTableau: &gt; 2 years\nPyTorch: 5,000 lines\nTensorflow: 5,000 lines\nScikit-Learn: 3,000 lines\nSQL: 3,000 lines\nDocker: &lt; 1 year\nAWS/Azure: 1 year"
  },
  {
    "objectID": "about_me.html#contact-me",
    "href": "about_me.html#contact-me",
    "title": "Farhan Sadeek",
    "section": "",
    "text": "Email: farhansadeek019@gmail.com\nLinkedIn: farhansadeekde110\nX: SadeekFarhan21"
  }
]